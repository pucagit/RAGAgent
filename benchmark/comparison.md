# **CH∆Ø∆†NG 4: K·∫æT QU·∫¢ TH·ª∞C NGHI·ªÜM**

## **1. M·ª•c ti√™u**

Th·ª±c nghi·ªám nh·∫±m **ƒë√°nh gi√° hi·ªáu nƒÉng truy h·ªìi (retrieval performance)** c·ªßa c√°c m√¥ h√¨nh embedding m√£ ngu·ªìn m·ªü trong h·ªá th·ªëng **Retrieval-Augmented Generation (RAG)**, t·∫≠p trung v√†o:

* So s√°nh ƒë·ªô ch√≠nh x√°c gi·ªØa c√°c m√¥ h√¨nh theo lo·∫°i c√¢u h·ªèi;
* Ph√¢n t√≠ch ƒë·∫∑c t√≠nh k·ªπ thu·∫≠t ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng bi·ªÉu di·ªÖn ng·ªØ nghƒ©a;
* L·ª±a ch·ªçn m√¥ h√¨nh ph√π h·ª£p cho m√¥i tr∆∞·ªùng RAG c·ª•c b·ªô trong lƒ©nh v·ª±c b·∫£o m·∫≠t.

---

## **2. Thi·∫øt l·∫≠p**

* **Dataset:** [*Cybersecurity Attack Dataset*](https://huggingface.co/datasets/pucavv/Cybersecurity_Attack) (~18.29MB, ~14000 rows).
* **C√¥ng c·ª•:** PostgreSQL + `pgai Vectorizer`, ch·∫°y embedding qua Ollama.
* **C√°c m√¥ h√¨nh th·ª≠ nghi·ªám:** 8 m√¥ h√¨nh embedding m√£ ngu·ªìn m·ªü.
  
| M√¥ h√¨nh embedding               |    Parameters    | Dimensions |       Size | 
| ------------------------------- | ---------------- | ---------- | ---------- |
| **mxbai-embed-large**           |            	334M |       1024 |      670MB |
| **nomic-embed-text**            |            	137M |        768 |      274MB | 
| **bge-m3**                      |             567M |       1024 |      1.2GB |
| **qwen3-embedding:0.6b**        |             0.6B |       1024 |      639MB |
| **qwen3-embedding:4b**          |               4B |       2560 |      2.5GB |
| **embeddinggemma:300m**         |             300M |        768 |      622MB |
| **snowflake-arctic-embed:335m** |             335M |       1024 |      669MB |
| **granite-embedding:278m**      |             278M |        768 |      563MB |

* **Ph√¢n lo·∫°i c√¢u h·ªèi:**

| **Lo·∫°i c√¢u h·ªèi**          | **M√¥ t·∫£**                                              | **Tr·ªçng t√¢m ƒë√°nh gi√°**                                                                                            |
| ------------------------- | ------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------- |
| **C√¢u h·ªèi ng·∫Øn**          | C√¢u h·ªèi ƒë∆°n gi·∫£n, tr·ª±c ti·∫øp, c√≥ ƒë·ªô d√†i d∆∞·ªõi 10 t·ª´      | Hi·ªÉu ng·ªØ nghƒ©a (ki·ªÉm tra kh·∫£ nƒÉng hi·ªÉu c∆° b·∫£n)                                                                    |
| **C√¢u h·ªèi d√†i**           | C√¢u h·ªèi chi ti·∫øt, to√†n di·ªán, ch·ª©a c√°c th√¥ng tin c·ª• th·ªÉ | Truy h·ªìi theo ng·ªØ c·∫£nh (ki·ªÉm tra kh·∫£ nƒÉng x·ª≠ l√Ω c√¢u h·ªèi s√¢u v√† nhi·ªÅu chi ti·∫øt)                                    |
| **C√¢u h·ªèi tr·ª±c ti·∫øp**     | ƒê·ªÅ c·∫≠p ƒë·∫øn n·ªôi dung ƒë∆∞·ª£c n√™u r√µ trong vƒÉn b·∫£n          | Hi·ªÉu ng·ªØ nghƒ©a (ki·ªÉm tra kh·∫£ nƒÉng truy h·ªìi th√¥ng tin kh·ªõp ch√≠nh x√°c)                                              |
| **C√¢u h·ªèi h√†m √Ω**         | C√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh, ƒë√≤i h·ªèi kh·∫£ nƒÉng suy lu·∫≠n   | Truy h·ªìi theo ng·ªØ c·∫£nh (ki·ªÉm tra kh·∫£ nƒÉng hi·ªÉu √Ω nghƒ©a v∆∞·ª£t ra ngo√†i n·ªôi dung hi·ªÉn th·ªã)                           |
| **C√¢u h·ªèi kh√¥ng r√µ r√†ng** | C√¢u h·ªèi m∆° h·ªì ho·∫∑c ƒëa nghƒ©a                            | Ki·ªÉm tra c·∫£ hai ti√™u ch√≠ ƒë√°nh gi√° (kh·∫£ nƒÉng c·ªßa m√¥ h√¨nh trong vi·ªác x·ª≠ l√Ω s·ª± kh√¥ng ch·∫Øc ch·∫Øn v√† di·ªÖn gi·∫£i √Ω nghƒ©a) |


* **Ph∆∞∆°ng ph√°p:** 
  1. Chu·∫©n b·ªã:
     - Dataset v·ªÅ Cybersecurity (~14000 rows)
     - Ch·ªçn ra 20 chunks ng·∫´u nhi√™n v√† t·∫°o c√°c c√¢u h·ªèi d·ª±a tr√™n ch√∫ng
  2. V·ªõi m·ªói model:
     - Vector h√≥a c·∫•u h·ªèi, dataset v·ªõi c√πng chi·∫øn thu·∫≠t (512 characters v·ªõi 50 character overlap)
     - Th·ª±c hi·ªán similarity search gi·ªØa c√°c ƒëo·∫°n chunk c·ªßa dataset v√† c√¢u h·ªèi
     - Ki·ªÉm tra trong `top-K` k·∫øt qu·∫£ c√≥ ch·ª©a ƒëo·∫°n chunk g·ªëc kh√¥ng
  3. T√≠nh to√°n hi·ªáu nƒÉng:
     - ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ
     - ƒê·ªô ch√≠nh x√°c d·ª±a tr√™n t·ª´ng lo·∫°i c√¢u h·ªèi
---

## **3. K·∫øt qu·∫£ t·ªïng h·ª£p**

| M√¥ h√¨nh embedding               | Accuracy t·ªïng th·ªÉ |      Short |       Long |     Direct |    Implied |    Unclear |
| ------------------------------- | ----------------: | ---------: | ---------: | ---------: | ---------: | ---------: |
| **mxbai-embed-large**           |            57.96% |     45.00% |     93.75% |     53.75% |     73.75% |     25.00% |
| **nomic-embed-text**            |            59.20% |     43.75% |     95.00% |     55.00% |     73.75% |     30.00% |
| **bge-m3**                      |        **63.93%** | **55.00%** | **95.00%** | **61.25%** | **80.00%** | **30.00%** |
| **qwen3-embedding:0.6b**        |            53.48% |     28.75% |     91.25% |     50.00% |     75.00% |     23.75% |
| **qwen3-embedding:4b**          |            57.46% |     37.50% |     96.25% |     55.00% |     77.50% |     22.50% |
| **embeddinggemma:300m**         |            29.60% |      7.50% |     68.75% |     28.75% |     36.25% |      7.50% |
| **snowflake-arctic-embed:335m** |            38.06% |     30.00% |     68.75% |     35.00% |     46.25% |     11.25% |
| **granite-embedding:278m**      |            59.70% |     48.75% |     93.75% |     52.50% |     77.50% |     27.50% |

---

## **4. Ph√¢n t√≠ch k·∫øt qu·∫£**

### **4.1. Nh·∫≠n x√©t t·ªïng th·ªÉ**

* **BGE-M3** ƒë·∫°t hi·ªáu nƒÉng cao nh·∫•t (63.93%), th·ªÉ hi·ªán r√µ kh·∫£ nƒÉng bi·ªÉu di·ªÖn ng·ªØ nghƒ©a v√† kh·ªõp ng·ªØ c·∫£nh t·ªët.
  ‚Üí M√¥ h√¨nh n√†y s·ª≠ d·ª•ng ki·∫øn tr√∫c *multi-vector dense embedding*, ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n nhi·ªÅu t·∫≠p d·ªØ li·ªáu ƒë·ªëi ng·ªØ nghƒ©a (contrastive datasets) n√™n t·∫°o ra kh√¥ng gian vector c√≥ t√≠nh ph√¢n bi·ªát cao.

* **Nomic-embed-text** v√† **Granite-embedding** ƒë·∫°t hi·ªáu nƒÉng ·ªïn ƒë·ªãnh (~59‚Äì60%), ph·∫£n √°nh thi·∫øt k·∫ø c√¢n b·∫±ng gi·ªØa k√≠ch th∆∞·ªõc m√¥ h√¨nh v√† kh·∫£ nƒÉng hi·ªÉu ng·ªØ nghƒ©a.
  ‚Üí Hai m√¥ h√¨nh n√†y ƒë∆∞·ª£c t·ªëi ∆∞u cho ‚Äúgeneral text representation‚Äù, ph√π h·ª£p cho truy v·∫•n ƒëa lƒ©nh v·ª±c.

* **Qwen3 (0.6B v√† 4B)** cho th·∫•y s·ª± thi·∫øu ·ªïn ƒë·ªãnh: m·∫∑c d√π b·∫£n 4B l·ªõn h∆°n, nh∆∞ng ƒë·ªô ch√≠nh x√°c kh√¥ng v∆∞·ª£t tr·ªôi.
  ‚Üí Nguy√™n nh√¢n l√† v√¨ Qwen3 t·∫≠p trung hu·∫•n luy·ªán cho sinh ng√¥n ng·ªØ (language modeling) h∆°n l√† embedding retrieval.

* **Gemma v√† Arctic** c√≥ ƒë·ªô ch√≠nh x√°c r·∫•t th·∫•p, cho th·∫•y **embedding space c·ªßa ch√∫ng kh√¥ng ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho semantic retrieval** ‚Äî ph√π h·ª£p h∆°n v·ªõi inference ho·∫∑c nhi·ªám v·ª• ph√¢n lo·∫°i ƒë∆°n gi·∫£n.

---

### **4.2. Ph√¢n t√≠ch theo lo·∫°i c√¢u h·ªèi**

| Lo·∫°i c√¢u h·ªèi | M√¥ h√¨nh d·∫´n ƒë·∫ßu     | Ph√¢n t√≠ch                                                                                   |
| ------------ | ------------------- | ------------------------------------------------------------------------------------------- |
| **Short**    | BGE-M3 (55%)        | C√≥ kh·∫£ nƒÉng encode t·ª´ v·ª±ng ng·∫Øn ch√≠nh x√°c nh·ªù hu·∫•n luy·ªán ƒëa t·∫ßng v·ªõi contrastive loss.      |
| **Long**     | Qwen3-4B (96.25%)   | L·ª£i th·∫ø ·ªü bi·ªÉu di·ªÖn ng·ªØ c·∫£nh d√†i, do dung l∆∞·ª£ng model l·ªõn gi√∫p gi·ªØ ƒë∆∞·ª£c th√¥ng tin d√†i h·∫°n.  |
| **Direct**   | BGE-M3 (61.25%)     | Hi·ªÉu t·ªët n·ªôi dung xu·∫•t hi·ªán r√µ trong ƒëo·∫°n vƒÉn; embedding ƒëa chi·ªÅu gi√∫p ph√¢n bi·ªát ch√≠nh x√°c. |
| **Implied**  | BGE-M3 (80%)        | M·∫°nh nh·∫•t v·ªÅ suy lu·∫≠n ng·ªØ nghƒ©a ‚Äì k·∫øt qu·∫£ c·ªßa vi·ªác hu·∫•n luy·ªán tr√™n NLI/STSB.                |
| **Unclear**  | Nomic, BGE-M3 (30%) | D√π m·ªçi m√¥ h√¨nh ƒë·ªÅu y·∫øu ·ªü truy v·∫•n m∆° h·ªì, BGE-M3 v√† Nomic √≠t b·ªã nhi·ªÖu nh·∫•t.                  |

---

### **4.3. Gi·∫£i th√≠ch l√Ω thuy·∫øt**

1. **C·∫•u tr√∫c hu·∫•n luy·ªán contrastive learning** (v√≠ d·ª• nh∆∞ c·ªßa BGE, Nomic) gi√∫p m√¥ h√¨nh h·ªçc c√°ch ph√¢n t√°ch c√°c vƒÉn b·∫£n t∆∞∆°ng t·ª± v√† kh√°c bi·ªát trong kh√¥ng gian vector ‚Üí tƒÉng ƒë·ªô ch√≠nh x√°c truy h·ªìi.
2. **Embedding dimension v√† s·ªë l∆∞·ª£ng c·∫∑p d·ªØ li·ªáu hu·∫•n luy·ªán** ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn kh·∫£ nƒÉng kh·ªõp ng·ªØ nghƒ©a. M√¥ h√¨nh l·ªõn nh∆∞ng kh√¥ng ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë√∫ng c√°ch (nh∆∞ Qwen3-4B) s·∫Ω kh√¥ng t·ªëi ∆∞u cho retrieval.
3. **C√°c m√¥ h√¨nh nh·ªè** c√≥ kh√¥ng gian vector h·∫πp h∆°n ‚Üí d·ªÖ x·∫£y ra hi·ªán t∆∞·ª£ng ‚Äúsemantic collapse‚Äù, khi·∫øn c√¢u h·ªèi t∆∞∆°ng t·ª± kh√≥ ƒë∆∞·ª£c ph√¢n bi·ªát.

---

### **4.4. Bi·ªÉu ƒë·ªì minh h·ªça**

![Grouped Column Chart](evaluation_data/grouped_column.png)

#### üîπ *H√¨nh 4.1 ‚Äì Bi·ªÉu ƒë·ªì c·ªôt nh√≥m (Grouped Column Chart)*

Bi·ªÉu ƒë·ªì cho th·∫•y BGE-M3 n·ªïi b·∫≠t nh·∫•t ·ªü t·∫•t c·∫£ nh√≥m c√¢u h·ªèi, ƒë·∫∑c bi·ªát ‚ÄúImplied‚Äù v√† ‚ÄúDirect‚Äù.

---

## **5. K·∫øt lu·∫≠n ch∆∞∆°ng**

1. **BGE-M3** l√† m√¥ h√¨nh **t·ªëi ∆∞u nh·∫•t** cho t√°c v·ª• RAG c·ª•c b·ªô, ƒë·∫°t hi·ªáu nƒÉng cao nh·∫•t ·ªü c·∫£ ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ v√† t·ª´ng lo·∫°i truy v·∫•n.
2. **Nomic-embed-text** v√† **Granite-278M** l√† l·ª±a ch·ªçn nh·∫π, th√≠ch h·ª£p cho tri·ªÉn khai n·ªôi b·ªô v·ªõi t√†i nguy√™n h·∫°n ch·∫ø.
3. **Qwen3-4B** c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω ng·ªØ c·∫£nh d√†i t·ªët, nh∆∞ng ch∆∞a v∆∞·ª£t tr·ªôi do kh√¥ng t·ªëi ∆∞u ƒë·∫∑c th√π cho retrieval.
4. **Gemma v√† Arctic** ch·ªâ n√™n d√πng cho th·ª≠ nghi·ªám ho·∫∑c m√¥ ph·ªèng pipeline RAG.
5. V·ªõi c√°c ·ª©ng d·ª•ng RAG an ninh m·∫°ng, l·ª±a ch·ªçn t·ªët nh·∫•t l√† **BGE-M3** ho·∫∑c **Nomic-embed-text**, ƒë·∫£m b·∫£o c√¢n b·∫±ng gi·ªØa hi·ªáu nƒÉng, t·ªëc ƒë·ªô v√† t√≠nh ri√™ng t∆∞ d·ªØ li·ªáu.

## **6. Tham kh·∫£o**
https://www.tigerdata.com/blog/finding-the-best-open-source-embedding-model-for-rag